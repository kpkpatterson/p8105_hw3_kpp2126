---
title: "Homework 3"
author: "Kevin Patterson"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continous.colour = "viridis",
  ggplot2.continous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete  = scale_fill_viridis_d
```

# Problem 1
```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by user. There are user and order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```
There are 134 aisles and the most items ordered are from fresh vegetables aisle (n=150,609), fresh fruits aisle (n=150,473), followed by packaged vegetables and fruits aisle (n=78,493).

Let's make a plot
```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
Let's make a table
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```
Let's make a table on Apples vs. Ice Cream.
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

# Problem 2
Load, tidy, wrangle data.
```{r}
accel_df = read_csv("./accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    cols = activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_counts") %>%
  mutate(week_type=case_when(day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "Weekday",
                           day %in% c("Saturday","Sunday") ~ "Weekend")
         )
```
Tidied dataset
```{r}
accel_df%>%tibble()
```
This new dataset contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. There are 50,400 observations of activity counts that correspond to the minute they were recorded. There are 6 variables that include 5 weeks of accelerometer observations, a `day_id` variable that corresponds to each day of the study (n = 35 days), and a `week_type` variable that indicates whether an observation was on a weekday or on the weekend.

Aggregate dataset across minutes to create a total activity variable for each day.
```{r}

```


